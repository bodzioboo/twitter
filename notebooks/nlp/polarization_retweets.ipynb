{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of polarization in retweets and replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../src')\n",
    "PATH = '/home/piotr/projects/twitter'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Tweet-level polarization for each of the Tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_polarization = dict()\n",
    "PATH_SCORES = os.path.join(PATH, 'results/polarization/tweet_polarization.json')\n",
    "for df in tqdm(read_window(PATH_DATA, window_size=7,  batch_size=1, \n",
    "                           day_from=START, day_to=END, dtype=dtypes, filter_fun=ff)):\n",
    "\n",
    "    #fit vectorizer on all vocabulary:\n",
    "    model = ModelPolarization(parties = [\"gov\", \"opp\"], limit = 40, ngram_range = (1,2), log = 20)\n",
    "    model.prefit(df[\"lemmatized\"].astype(str).to_numpy())\n",
    "    date_range = sorted(pd.to_datetime(df.day.unique()))\n",
    "    mid_date = date_range[3].date().strftime('%Y-%m-%d')\n",
    "    df = df[df['day'] == mid_date]\n",
    "    #keep only unique across party and text:\n",
    "    orig = df.drop_duplicates(subset = ['lemmatized','source'])\n",
    "    #estimate:\n",
    "    model = ModelPolarization(parties = [\"gov\", \"opp\"], limit = 10, ngram_range = (1,2))\n",
    "    est = model.estimate(orig['source'], orig['user-id_str'], orig['lemmatized'], \n",
    "                     text_id = orig['id_str'], level ='speech', leave_out = True)\n",
    "    orig['pol'] = orig['id_str'].map(est)\n",
    "    #map the polarization scores on non-unique tweets:\n",
    "    pol_dict = orig[['full_text','source','pol']].set_index(['full_text','source'])['pol'].to_dict()\n",
    "    df['pol'] = df.set_index(['full_text','source']).index.map(pol_dict)\n",
    "    df = df[['Repliesid_str','pol']].set_index('id_str')['pol'].to_dict()\n",
    "    #save:\n",
    "    tweets_polarization.update(df)\n",
    "json.dump(tweets_polarization, open(PATH_SCORES, 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Overall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweets = pd.DataFrame()\n",
    "for dat in tqdm(read_files(PATH_DATA, day_from = START, day_to = END, dtype = dtypes, filter_fun = ff), total = 144):\n",
    "    dat = dat[dat.retweet]\n",
    "    dat['pol'] = dat['id_str'].map(tweets_polarization)\n",
    "    dat = dat.groupby(['source','full_text', 'pol']).size().reset_index()\n",
    "    dat.columns = ['source', 'full_text','pol', 'n']\n",
    "    retweets = retweets.append(dat)\n",
    "retweets.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweets.plot.scatter('num','pol', figsize = (12, 8))\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Number of retweets')\n",
    "plt.ylabel('Partisanship')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Day-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = retweets.groupby(['day']).corr().reset_index()\n",
    "correlations[correlations['level_1'] == 'pol'].set_index('day')['num'].plot(rot = 45, figsize = (12, 8))\n",
    "plt.ylabel('Partisanship-popularity correlation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Week- level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweets['week'] = pd.to_datetime(retweets['day']).dt.week\n",
    "correlations = retweets.groupby(['week']).corr().reset_index()\n",
    "correlations[correlations['level_1'] == 'pol'].set_index('week')['num'].plot(rot = 45, figsize = (12, 8))\n",
    "plt.ylabel('Partisanship-popularity correlation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. By topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = retweets.groupby(['day', 'topic']).corr().reset_index()\n",
    "correlations = correlations[correlations['level_2'] == 'pol']\n",
    "fig, ax = plt.subplots(5, 3, figsize = (16, 12), sharex = True, sharey = True)\n",
    "ax = ax.ravel()\n",
    "for i, (topic, df) in enumerate(correlations.groupby('topic')):\n",
    "    ax[i].plot(df['day'], df['num'])\n",
    "    ax[i].set_title(f'Topic : {topic}')\n",
    "    ax[i].xaxis.set_tick_params(rotation=45)\n",
    "    ax[i].xaxis.set_ticks(np.arange(len(df['day']), step = 20))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['created_at', 'full_text','id_str','user-id_str','in_reply_to_status_id_str']\n",
    "all_replies = pd.DataFrame(columns = cols)\n",
    "for fname in tqdm([f for f in os.listdir(PATH_DATA) if '.csv' in f]):\n",
    "    dat = pd.read_csv(os.path.join(PATH_DATA, fname), index_col = 0, dtype = str)\n",
    "    replies = dat[dat['in_reply_to_status_id_str'].notna()]\n",
    "    all_replies = all_replies.append(replies[cols])\n",
    "counts = all_replies.groupby('in_reply_to_status_id_str').size().to_dict()\n",
    "all_replies['n'] = all_replies['in_reply_to_status_id_str'].map(counts)\n",
    "all_replies['date'] = pd.to_datetime('')\n",
    "all_replies = all_replies.sort_values(['in_reply_to_status_id_str','date'])\n",
    "all_replies['order'] = all_replies.groupby(['in_reply_to_status_id_str']).cumcount()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp)",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
