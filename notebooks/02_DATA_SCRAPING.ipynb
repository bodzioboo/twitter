{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "PATH = '/home/piotr/projects/twitter/'\n",
    "sys.path.append('/home/piotr/projects/twitter/src')\n",
    "import itertools\n",
    "import operator\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm, trange\n",
    "from time import sleep\n",
    "import gc\n",
    "import os\n",
    "import nltk\n",
    "from dask import array as da\n",
    "import re\n",
    "import time\n",
    "import itertools\n",
    "from collections import OrderedDict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from upsetplot import plot as setplot\n",
    "from tweepy import API, AppAuthHandler, Cursor\n",
    "from twitter_tools.scrapers import TwitterSampler\n",
    "from twitter_tools.config import consumer_key, consumer_secret, access_token, access_secret\n",
    "from matplotlib import pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seed profiles to obtain the polarized followers from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gov_seed = ['@D_Tarczynski', '@BeataSzydlo', '@Macierewicz_A', \n",
    "              '@KrystPawlowicz', '@StKarczewski', '@MorawieckiM', \n",
    "              '@ZiobroPL', '@jbrudzinski', '@PatrykJaki', '@mblaszczak']\n",
    "opp_seed = ['@SchetynadlaPO', '@bbudka', '@KLubnauer', '@Arlukowicz', \n",
    "              '@profGrodzki', '@RyszardPetru', '@trzaskowski_', \n",
    "              '@TomaszSiemoniak', '@Gasiuk_Pihowicz']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export as table: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tbl = pd.DataFrame(dict(source = ['government', 'opposition'], \n",
    "                        username = [\", \".join(gov_seed), \", \".join(opp_seed)]))\n",
    "pd.set_option('display.max_colwidth', 150)\n",
    "open(os.path.join(PATH, 'final/tables/seed_profiles.tex'), 'w').write(tbl.to_latex(index=False, \n",
    "                                                                                   column_format='lp{1.8cm}p{5cm}'))\n",
    "tbl.to_csv(os.path.join(PATH, 'final/tables/seed_profiles.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get followers of politician profiles\n",
    "The method `getFollowers` from `FollowerScrapers` given a list of Twitter account names returns dictionary of the account names from the list associatied with list of IDs of their followers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = AppAuthHandler(consumer_key = consumer_key, consumer_secret = consumer_secret)\n",
    "api = API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get followers of government politicians profiles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(\"../data/sample/government_followers.json\"):\n",
    "    government_followers = json.load(open(\"../data/sample/government_followers.json\",\"r\"))\n",
    "else:\n",
    "    government = [api.get_user(name).id for name in gov_seed]\n",
    "    government_followers = scraper.getFollowers(government, \"../data/sample/government_followers.json\")\n",
    "    json.dump(government, open(\"../data/sample/government_followers.json\", 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get followers of opposition politicians profiles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(\"../data/sample/opposition_followers.json\"):\n",
    "    opposition_followers = json.load(open(\"../data/sample/opposition_followers.json\",\"r\"))\n",
    "else:\n",
    "    opposition = [api.get_user(name).id for name in opp_seed]\n",
    "    opposition_followers = scraper.getFollowers(opposition, \"../data/sample/opposition_followers.json\")\n",
    "    json.dump(opposition_followers, open(\"../data/sample/opposition_followers.json\", 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at the intersections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect_followers(followers_dict):\n",
    "    profile_names = list(followers_dict.keys())\n",
    "    followers_intersections = [pd.Series(True, index=list(elements), name=name)\n",
    "                      for name, elements in followers_dict.items()] #set all values to true where id exists\n",
    "    followers_intersections = pd.concat(followers_intersections,sort = False,axis = 1) #concatanate\n",
    "    followers_intersections = followers_intersections.fillna(False).reset_index() #fill nas and put id to columns\n",
    "    followers_intersections = followers_intersections.groupby(profile_names).count() #get counts\n",
    "    return followers_intersections[\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opposition_followers = {k:set(v) for k,v in opposition_followers.items()}\n",
    "setplot(intersect_followers(opposition_followers),show_percentages = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "government_followers = {k:set(v) for k,v in government_followers.items()}\n",
    "government_intersections = intersect_followers(government_followers)\n",
    "setplot(government_intersections,show_percentages = True)\n",
    "plt.show()\n",
    "print(pd.DataFrame(government_intersections).sort_values(by = \"index\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Narrow down the population to political partisans\n",
    "The method `subsetFollowers` given two followers dictionaries such as the ones created by the `getFollowers` method returns two lists of followers, each that had at least $n$ overlap within one dictionary and at most $m$ overlap with the other. Using this method I filtered out two distinct populations of users - *opposition partisans* following at least 6 opposition politicians and at most 4 government politicians and *government partisans* following at least 6 government politicians and and most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(\"../data/sample/gov_partisans.p\") and os.path.isfile(\"../data/sample/opp_partisans.p\"):\n",
    "    gov_partisans = pickle.load(open(\"../data/sample/gov_partisans.p\",\"rb\"))\n",
    "    opp_partisans = pickle.load(open(\"../data/sample/opp_partisans.p\",\"rb\"))\n",
    "else:\n",
    "    gov_partisans, opp_partisans = scraper.subsetFollowers(government_followers, opposition_followers, 6, 4)\n",
    "    pickle.dump(gov_partisans,open(\"../data/sample/gov_partisans.p\",\"wb\"))\n",
    "    pickle.dump(opp_partisans,open(\"../data/sample/opp_partisans.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of these groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35422 opposition partisans and 26465 government partisans were filtered\n"
     ]
    }
   ],
   "source": [
    "print(\"{} opposition partisans and {} government partisans were filtered\".format(len(gov_partisans),len(opp_partisans)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, there's no overlap between the two groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(gov_partisans).intersection(set(opp_partisans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get population info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(\"../data/sample/gov_partisans_info.csv\"):\n",
    "    gov_followers_info = pd.read_csv(\"../data/sample/gov_partisans_info.csv\", index_col = 0)\n",
    "else:\n",
    "    scraper.getFollowersData(gov_partisans, \"../data/sample/gov_partisans_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(\"../data/sample/opp_partisans_info.csv\"):\n",
    "    opp_followers_info = pd.read_csv(\"../data/sample/opp_partisans_info.csv\", index_col = 0)\n",
    "else:\n",
    "    scraper.getFollowersData(opp_partisans, \"../data/sample/opp_partisans_info.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get samples:\n",
    "Given the above partisans, I sampled 5000 from each group that had tweeted at least once since the 1st of March."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_date(df, date):\n",
    "    \n",
    "    #filter out examples with erroneous date record:\n",
    "    match_date = \"[A-Z][a-z]{2} [A-Z][a-z]{2} \\d{2} \\d{2}:\\d{2}:\\d{2} \\+\\d{4} \\d{4}\"\n",
    "    index_good = df[\"status-created_at\"].astype(str).apply(lambda x: re.search(match_date, x) != None)\n",
    "    df = df[index_good]\n",
    "    \n",
    "    #parse date\n",
    "    dates = pd.to_datetime(df['status-created_at'], format = \"%a %b %d %H:%M:%S +0000 %Y\")\n",
    "    \n",
    "    #return date above limit\n",
    "    return df[\"id_str\"][dates > date].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(\"../data/sample/opp_sample.pickle\"):\n",
    "    opp_sample = pickle.load(open(\"../data/sample/opp_sample.pickle\", \"rb\"))\n",
    "else:\n",
    "    opp_sample = filter_date(opp_followers_info, datetime.datetime.strptime(\"01/03/2020\", \"%d/%m/%Y\"))\n",
    "    opp_sample = opp_sample[:5000]\n",
    "    pickle.dump(opp_sample, open(\"../data/sample/opp_sample.pickle\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(\"../data/sample/gov_sample.pickle\"):\n",
    "    gov_sample = pickle.load(open(\"../data/sample/opp_sample.pickle\", \"rb\"))\n",
    "else:\n",
    "    \n",
    "    gov_sample = filter_date(gov_followers_info, datetime.datetime.strptime(\"01/03/2020\", \"%d/%m/%Y\"))\n",
    "    gov_sample = gov_sample[:5000]\n",
    "    pickle.dump(gov_sample, open(\"../data/sample/gov_sample.pickle\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [12:00<00:00, 72.09s/it]\n",
      "100%|██████████| 10/10 [10:46<00:00, 64.67s/it]\n",
      "100%|██████████| 10/10 [10:41<00:00, 64.13s/it]\n",
      "100%|██████████| 10/10 [12:11<00:00, 73.17s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'    \\ngov_partisans = np.array(government_superset)[(gov_in_gov >= 6) & (gov_in_opp <= 4)].tolist()\\nopp_partisans = np.array(opposition_superset)[(opp_in_opp >= 6) & (opp_in_gov <= 4)].tolist()\\n\\n\\npickle.dump(gov_partisans, open(\"data/gov_partisans.pickle\",\"wb\"))\\npickle.dump(opp_partisans, open(\"data/opp_partisans.pickle\",\"wb\"))\\n\\n\\n#no overlap\\nset(gov_partisans).intersection(set(opp_partisans))\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function to filter out elements of superset that occur in at most/least n subsets\n",
    "def how_many(superset,subsets):\n",
    "    superset = np.array(superset)[:,np.newaxis] #convert to Nx1 nparray\n",
    "    superset = da.from_array(superset, chunks = (2000,1)) #convert to dask\n",
    "    count = np.zeros(superset.shape[0]).astype(\"int8\")\n",
    "    for subset in tqdm(subsets):\n",
    "        tmp = da.from_array(subset)\n",
    "        count += (superset == tmp).sum(axis = 1).compute().astype(\"int8\")\n",
    "        gc.collect()\n",
    "    return count\n",
    "\n",
    "government_superset = list(set(itertools.chain.from_iterable(government_followers.values())))\n",
    "government_subsets = list(government_followers.values())\n",
    "opposition_superset = list(set(itertools.chain.from_iterable(opposition_followers.values())))\n",
    "opposition_subsets = list(opposition_followers.values())\n",
    "\n",
    "\n",
    "gov_in_gov = how_many(government_superset, government_subsets) #how many gov profiles followed by each gov follower\n",
    "gov_in_opp = how_many(government_superset, opposition_subsets) #how many opp profiles followed by each gov follower\n",
    "opp_in_opp = how_many(opposition_superset, opposition_subsets) #how many opp profiles followed by each opp follower\n",
    "opp_in_gov = how_many(opposition_superset, government_subsets) #how many gov profiles followed by each opp follower\n",
    "pickle.dump([gov_in_gov,gov_in_opp,opp_in_opp,opp_in_gov], open(\"overlaps.pickle\",\"wb\"))\n",
    "\n",
    "    \n",
    "\"\"\"    \n",
    "gov_partisans = np.array(government_superset)[(gov_in_gov >= 6) & (gov_in_opp <= 4)].tolist()\n",
    "opp_partisans = np.array(opposition_superset)[(opp_in_opp >= 6) & (opp_in_gov <= 4)].tolist()\n",
    "\n",
    "\n",
    "pickle.dump(gov_partisans, open(\"data/gov_partisans.pickle\",\"wb\"))\n",
    "pickle.dump(opp_partisans, open(\"data/opp_partisans.pickle\",\"wb\"))\n",
    "\n",
    "\n",
    "#no overlap\n",
    "set(gov_partisans).intersection(set(opp_partisans))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "gov_partisans = np.array(government_superset)[(gov_in_gov > gov_in_opp)].tolist()\n",
    "opp_partisans = np.array(opposition_superset)[(opp_in_opp > opp_in_gov)].tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp)",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
