{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twitter_cleaner import TweetCleaner\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = TweetCleaner(\"cleaner.config\")\n",
    "cols = [\"\",\"created_at\",\"id_str\",\"user-id_str\", \"user-followers_count\", \n",
    "        \"full_text\", \"retweeted_status-full_text\",\"retweeted_status-id_str\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty run 100000\n",
      "Empty run 200000\n",
      "Empty run 300000\n",
      "Empty run 400000\n",
      "Empty run 500000\n",
      "Empty run 600000\n",
      "Empty run 700000\n",
      "Empty run 800000\n",
      "Empty run 900000\n",
      "Empty run 1000000\n",
      "Empty run 1100000\n",
      "Empty run 1200000\n",
      "Empty run 1300000\n",
      "Empty run 1400000\n",
      "Empty run 1500000\n",
      "Empty run 1600000\n",
      "Empty run 1700000\n",
      "Empty run 1800000\n",
      "Read 99078 tweets\n",
      "Number of problematic ids 0\n",
      "Preprocessed 99078 tweets\n",
      "Wrote 99078 tweets to file data/clean/gov_tweets_clean.csv\n",
      "Went through 1915378 rows\n",
      "Runtime 236.68221807479858\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "cleaner.clean(\"data/scraped/gov_tweets.csv\", \"data/clean/gov_tweets_clean.csv\", cols = cols, \n",
    "              path_stopwords = \"nlp/polish.stopwords.txt\", chunk_size = 100000)\n",
    "end = time.time()\n",
    "print(f\"Runtime {end - begin}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty run 100000\n",
      "Empty run 200000\n",
      "Empty run 300000\n",
      "Empty run 400000\n",
      "Empty run 500000\n",
      "Empty run 600000\n",
      "Empty run 700000\n",
      "Empty run 800000\n",
      "Empty run 900000\n",
      "Empty run 1000000\n",
      "Empty run 1100000\n",
      "Empty run 1200000\n",
      "Empty run 1300000\n",
      "Empty run 1400000\n",
      "Empty run 1500000\n",
      "Empty run 1600000\n",
      "Read 94175 tweets\n",
      "Number of problematic ids 0\n",
      "Preprocessed 94175 tweets\n",
      "Wrote 94175 tweets to file data/clean/opp_tweets_clean.csv\n",
      "Went through 1774547 rows\n",
      "Runtime 347.56292057037354\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "cleaner.clean(\"data/scraped/opp_tweets.csv\", \"data/clean/opp_tweets_clean.csv\", cols = cols, \n",
    "              path_stopwords = \"nlp/polish.stopwords.txt\", chunk_size = 100000)\n",
    "end = time.time()\n",
    "print(f\"Runtime {end - begin}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
